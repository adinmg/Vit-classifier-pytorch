# Urban Sound Classification Using PyTorch Vision Transformer

In this project, I've implemented the Vision Transformer (ViT) architecture to tackle the task of classifying urban sounds.

My goal is to replicate the ViT computer vision model described in the paper titled ["An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"](https://arxiv.org/abs/2010.11929) and adapt it for classifying urban sounds. I've applied this model to the [UrbanSound8K](https://www.kaggle.com/datasets/chrisfilo/urbansound8k) dataset.

## Libraries Used

To accomplish this project, I've utilized several libraries:

- [PyTorch](https://pytorch.org/)
- [Torchaudio](https://pytorch.org/audio/stable/index.html)
- [Torchinfo](https://github.com/TylerYep/torchinfo)
- [NumPy](https://numpy.org/)
- [Pandas](https://pandas.pydata.org/)
- [Scikit-learn](https://scikit-learn.org/stable/)
- [Seaborn](https://seaborn.pydata.org/)
- [Matplotlib](https://matplotlib.org/)

## Results

In the "results" folder, you can find a series of CSV files for comparing different image sizes. You can download them to your environment and inspect them in Section 9 with the `plot_summary()` function.
